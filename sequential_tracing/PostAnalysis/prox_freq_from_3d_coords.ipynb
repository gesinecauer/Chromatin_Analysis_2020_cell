{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='0'></a>\n",
    "# 0. Minimum required packages and settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='0.1'></a>\n",
    "## 0.1 import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382040\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(r\"..\", r\".\")))\n",
    "\n",
    "import source as ia\n",
    "\n",
    "print(os.getpid()) # print this so u can terminate through cmd / task-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='0.2'></a>\n",
    "## 0.2 parameters for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting setting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', serif='Arial')\n",
    "_font_size = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting parameters\n",
    "from source.figure_tools import _dpi,_single_col_width,_double_col_width,_single_row_height,_ref_bar_length, _ticklabel_size,_ticklabel_width,_font_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.gc Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder: /net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/zenodo_dl\n",
      "progress_folder: /net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress\n",
      "counts_folder: /net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/counts\n"
     ]
    }
   ],
   "source": [
    "# please change data_folder into the folder for downloaded dataset\n",
    "data_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"zenodo_dl\"))\n",
    "print(f\"data_folder: {data_folder}\")\n",
    "\n",
    "# [GC+] For saving partial progress\n",
    "progress_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"in_progress\"))\n",
    "print(f\"progress_folder: {progress_folder}\")\n",
    "os.makedirs(progress_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(progress_folder, '3d_coords'), exist_ok=True)\n",
    "os.makedirs(os.path.join(progress_folder, 'distances'), exist_ok=True)\n",
    "\n",
    "# [GC+] For saving final counts matrices\n",
    "counts_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"counts\"))\n",
    "print(f\"counts_folder: {counts_folder}\")\n",
    "os.makedirs(counts_folder, exist_ok=True)\n",
    "\n",
    "# # figure folder\n",
    "# # please specify location to save images\n",
    "# results_folder = os.path.abspath(os.path.join(r\"..\", r\"results\"))\n",
    "# parent_figure_folder = os.path.abspath(os.path.join(results_folder, \"figures\"))\n",
    "# os.makedirs(results_folder, exist_ok=True)\n",
    "# os.makedirs(parent_figure_folder, exist_ok=True)\n",
    "# print(f\"results_folder: {results_folder}\")\n",
    "# print(f\"parent_figure_folder: {parent_figure_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# please update as needed\n",
    "files_3dcoords = {\n",
    "    'chr21': {\n",
    "        'rep1': os.path.join(data_folder, 'chrom_trace',  'chr21.rep1.tsv'),\n",
    "        'rep2': os.path.join(data_folder, 'chrom_trace', 'chr21.rep2_cell_cycle.tsv')},\n",
    "    'chr2': {\n",
    "        'rep1': os.path.join(data_folder, 'chrom_trace',  'chr2.rep1.tsv'),\n",
    "        'rep2': os.path.join(data_folder, 'chrom_trace', 'chr2.rep2_p_arm.tsv')}}\n",
    "\n",
    "\n",
    "files_progress = {chrom: {} for chrom in files_3dcoords.keys()}\n",
    "\n",
    "for chrom in files_3dcoords.keys():\n",
    "    files_progress[chrom]['dir_coords3d'] = os.path.join(progress_folder, '3d_coords', chrom)\n",
    "    os.makedirs(files_progress[chrom]['dir_coords3d'], exist_ok=True)\n",
    "    \n",
    "    files_progress[chrom]['rep1'] = os.path.basename(files_3dcoords[chrom]['rep1']).replace('.tsv', '')\n",
    "    files_progress[chrom]['rep2'] = os.path.basename(files_3dcoords[chrom]['rep2']).replace('.tsv', '')\n",
    "    \n",
    "    for desc in ('distances.per_cell', 'distances.median', 'distances.mean', 'contacts.mean.cutoff500', 'contacts.per_cell.cutoff500'):\n",
    "        files_progress[chrom][desc] = os.path.join(progress_folder, 'distances', f'{chrom}.{desc}.npy')\n",
    "        \n",
    "\n",
    "files_progress['chr21']['proceed_with'] = 'chr21'\n",
    "files_progress['chr2']['proceed_with'] = files_progress['chr2']['rep1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please visit zenodo with DOI:10.5281/zenodo.3928890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.gc Function for working with sc distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sc_distances(filenames_chrom, distvec_per_cell=None, dis_mean=True, dis_median=True, contact_th=500):\n",
    "    from scipy.spatial.distance import pdist, squareform\n",
    "    \n",
    "    # distvec_per_cell_file = filenames_chrom['distances.per_cell']\n",
    "    # median_distance_map_file = filenames_chrom['distances.median']\n",
    "    # mean_distance_map_file = filenames_chrom['distances.mean']\n",
    "    # contacts_mean_file = filenames_chrom[f'contacts.mean.cutoff{contact_th}']\n",
    "    # contacts_percell_file = filenames_chrom[f'contacts.per_cell.cutoff{contact_th}']\n",
    "\n",
    "    if distvec_per_cell is None:\n",
    "        print('Loading sc distances...')\n",
    "        distvec_per_cell = np.load(filenames_chrom['distances.per_cell'])\n",
    "\n",
    "    # print(\"Converting distance vectors to 'squareform' matrices...\")\n",
    "    # distmap_per_cell = np.stack([squareform(distvec) for distvec in distvec_per_cell])\n",
    "\n",
    "    if dis_median:\n",
    "        print('Generate median distances across cells...')\n",
    "        median_distance_map = squareform(np.nanmedian(distvec_per_cell, axis=0))\n",
    "        np.save(filenames_chrom['distances.median'], median_distance_map) # [GC+] SAVE in-progress files\n",
    "\n",
    "    if dis_mean: # [GC+] generate MEAN distance map\n",
    "        print('Generate mean distances across cells...')\n",
    "        mean_distance_map = squareform(np.nanmean(distvec_per_cell, axis=0))\n",
    "        np.save(filenames_chrom['distances.mean'], mean_distance_map) # [GC+] SAVE in-progress files\n",
    "\n",
    "    if contact_th is not None:\n",
    "        print('Generate contacts...')\n",
    "        contacts_per_cell = (distvec_per_cell<contact_th).astype(int)\n",
    "        print('                 ...saving contacts<thresh per cell') # [GC+] generate contacts<thresh PER-CELL\n",
    "        np.save(filenames_chrom[f'contacts.per_cell.cutoff{contact_th}'], contacts_per_cell)\n",
    "        # contacts_mean = np.sum(contacts_per_cell, axis=0) / np.sum(np.isnan(distvec_per_cell)==False, axis=0)\n",
    "        contacts_mean = squareform(np.nanmean(contacts_per_cell, axis=0))\n",
    "        print('                 ...saving mean contacts across cells')\n",
    "        np.save(filenames_chrom[f'contacts.mean.cutoff{contact_th}'], contacts_mean) # [GC+] SAVE in-progress files\n",
    "\n",
    "    print('Done!')\n",
    "    \n",
    "    # print(\"Converting contact matrices to vectors...\") # Can be done with squareform or with triu_indices\n",
    "    # # contacts_per_cell = np.stack([squareform(contact_matrix) for contact_matrix in contacts_per_cell]) # equivalent to the below\n",
    "    # nbins = contacts_per_cell[-1]\n",
    "    # triu_idx = np.triu_indices(nbins, 1)\n",
    "    # contacts_per_cell = contacts_per_cell[:, triu_idx[0], triu_idx[1]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming that squareform is the same as using np.triu etc\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "size = 40\n",
    "arr = np.arange(size ** 2).reshape(size, size)\n",
    "arr = arr + arr.T\n",
    "np.fill_diagonal(arr, 0)\n",
    "\n",
    "arr_vec1 = squareform(arr)\n",
    "triu_idx = np.triu_indices(size, 1)\n",
    "arr_vec2 = arr[triu_idx]\n",
    "print(np.array_equal(arr_vec1, arr_vec2))\n",
    "\n",
    "arr_vec_arr1 = squareform(arr_vec1)\n",
    "arr_vec_arr2 = np.zeros([size, size])\n",
    "arr_vec_arr2[np.triu_indices(size, 1)] = arr_vec2\n",
    "arr_vec_arr2 += arr_vec_arr2.T\n",
    "print(np.array_equal(arr_vec_arr1, arr_vec_arr2))\n",
    "\n",
    "arrB = arr + 1\n",
    "arrC = arr + 1\n",
    "np.fill_diagonal(arrB, 0)\n",
    "np.fill_diagonal(arrC, 0)\n",
    "arrs = np.stack([arr, arrB, arrC])\n",
    "\n",
    "arrs_vec1 = np.stack([squareform(x) for x in arrs])\n",
    "arrs_vec2 = arrs[:, triu_idx[0], triu_idx[1]]\n",
    "print(np.array_equal(arrs_vec1, arrs_vec2))\n",
    "\n",
    "arrs.shape, arrs_vec2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "# Chromosome 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1.gc'></a>\n",
    "## 1.gc Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr21\n",
      "chr21.rep1\n",
      "chr21.rep2_cell_cycle\n"
     ]
    }
   ],
   "source": [
    "chrom = 'chr21'\n",
    "rep1_filename = files_3dcoords[chrom]['rep1']\n",
    "rep2_filename = files_3dcoords[chrom]['rep2']\n",
    "rep1 = files_progress[chrom]['rep1']\n",
    "rep2 = files_progress[chrom]['rep2']\n",
    "print(chrom); print(rep1); print(rep2)\n",
    "\n",
    "dir_3d_coords =  files_progress[chrom]['dir_coords3d']\n",
    "distmap_list_file = files_progress[chrom]['distances.per_cell']\n",
    "median_distance_map_file = files_progress[chrom]['distances.median']\n",
    "mean_distance_map_file = files_progress[chrom]['distances.mean']\n",
    "contacts_mean_c500_file = files_progress[chrom]['contacts.mean.cutoff500']\n",
    "contacts_percell_c500_file = files_progress[chrom]['contacts.per_cell.cutoff500']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 1.1 load chr21 replicate 1 \n",
    "\n",
    "(without cell cycle information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number', 'Gene names', 'Transcription', 'TSS ZXY(nm)']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3982c46d7dd04012bdfcd745313f45eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 genes exist in this dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4972ffbf8f6a4712aa02423f2e2b0f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/gs/vol1/home/gesine/local/anaconda3/envs/su2020/lib/python3.7/site-packages/ipykernel_launcher.py:101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep1_info_dict = {}\n",
    "with open(rep1_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep1_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep1_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep1 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep1_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep1_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep1_info_dict['Z(nm)'],rep1_info_dict['X(nm)'],\\\n",
    "                                         rep1_info_dict['Y(nm)'],rep1_info_dict['Genomic coordinate'],\\\n",
    "                                         rep1_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep1['chrom_ids'] = chr_ids\n",
    "data_rep1['region_names'] = region_names\n",
    "data_rep1['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep1['start_position_Mb'] = start_position_Mb\n",
    "data_rep1['end_position_Mb'] = end_position_Mb\n",
    "data_rep1['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep1_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep1_info_dict['Gene names'],\n",
    "                                                   rep1_info_dict['Transcription'],\n",
    "                                                   rep1_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep1_info_dict['Chromosome copy number'],\n",
    "                                                                  rep1_info_dict['Gene names'],\n",
    "                                                                  rep1_info_dict['Transcription'],\n",
    "                                                                  rep1_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep1['gene_names'] = gene_names\n",
    "    data_rep1['tss_zxys'] = tss_zxys_list\n",
    "    data_rep1['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep1_info_dict:\n",
    "    cell_cycle_types = np.unique(rep1_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep1_info_dict['Chromosome copy number'],rep1_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep1[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 1.2 load chr21 replicate 2 \n",
    "\n",
    "(with cell cycle information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number', 'Gene names', 'Transcription', 'TSS ZXY(nm)', 'Cell cycle state']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f2af26b3aa422598fb70cf94f27336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 genes exist in this dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c1e18321c0460a86fc4dcb70bc00bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/gs/vol1/home/gesine/local/anaconda3/envs/su2020/lib/python3.7/site-packages/ipykernel_launcher.py:101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a011cb0ff2874886a7c7c548f0ec5244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep2_info_dict = {}\n",
    "with open(rep2_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep2_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep2_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep2 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep2_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep2_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep2_info_dict['Z(nm)'],rep2_info_dict['X(nm)'],\\\n",
    "                                         rep2_info_dict['Y(nm)'],rep2_info_dict['Genomic coordinate'],\\\n",
    "                                         rep2_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep2['chrom_ids'] = chr_ids\n",
    "data_rep2['region_names'] = region_names\n",
    "data_rep2['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep2['start_position_Mb'] = start_position_Mb\n",
    "data_rep2['end_position_Mb'] = end_position_Mb\n",
    "data_rep2['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep2_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep2_info_dict['Gene names'],\n",
    "                                                   rep2_info_dict['Transcription'],\n",
    "                                                   rep2_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep2_info_dict['Chromosome copy number'],\n",
    "                                                                  rep2_info_dict['Gene names'],\n",
    "                                                                  rep2_info_dict['Transcription'],\n",
    "                                                                  rep2_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep2['gene_names'] = gene_names\n",
    "    data_rep2['tss_zxys'] = tss_zxys_list\n",
    "    data_rep2['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep2_info_dict:\n",
    "    cell_cycle_types = np.unique(rep2_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep2_info_dict['Chromosome copy number'],rep2_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep2[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.3 combine two datasets\n",
    "\n",
    "in most of panels we combined chromosomes from two replicates for better statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chromosomes: 12149\n"
     ]
    }
   ],
   "source": [
    "data_combined = {}\n",
    "for _k in data_rep1:\n",
    "    if _k in data_rep2:\n",
    "        # concatenate if this is some chromosomal data\n",
    "        if len(data_rep1[_k]) == len(data_rep1[\"chrom_ids\"]):\n",
    "            data_combined[_k] = np.concatenate([data_rep1[_k],data_rep2[_k]])\n",
    "        # directly merge if this is some shared information\n",
    "        elif (np.array(data_rep1[_k]) == np.array(data_rep2[_k])).all():\n",
    "            data_combined[_k] = data_rep1[_k]\n",
    "            \n",
    "print('Number of chromosomes:', len(data_combined['chrom_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Save current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {chrom: data_combined, rep1: data_rep1, rep2: data_rep2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== chr21 ========\n",
      "chrom_ids            ndarray    (12149,)\n",
      "dna_zxys             ndarray    (12149, 651, 3)\n",
      "tss_zxys             ndarray    (12149, 84, 3)\n",
      "trans_pfs            ndarray    (12149, 84)\n",
      "\n",
      "======== chr21.rep1 ========\n",
      "chrom_ids            ndarray    (7591,)\n",
      "dna_zxys             ndarray    (7591, 651, 3)\n",
      "tss_zxys             ndarray    (7591, 84, 3)\n",
      "trans_pfs            ndarray    (7591, 84)\n",
      "\n",
      "======== chr21.rep2_cell_cycle ========\n",
      "chrom_ids            ndarray    (4558,)\n",
      "dna_zxys             ndarray    (4558, 651, 3)\n",
      "tss_zxys             ndarray    (4558, 84, 3)\n",
      "trans_pfs            ndarray    (4558, 84)\n",
      "G1_flags             ndarray    (4558,)\n",
      "G2/S_flags           ndarray    (4558,)\n",
      "\n",
      "======== BOTH REPS ========\n",
      "params               dict       0\n",
      "region_names         ndarray    (651,)\n",
      "mid_position_Mb      ndarray    (651,)\n",
      "start_position_Mb    ndarray    (651,)\n",
      "end_position_Mb      ndarray    (651,)\n",
      "gene_names           list       84\n",
      "\n",
      "\n",
      "Is 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\n",
      "chr21                     ✓\n",
      "chr21.rep1                ✓\n",
      "chr21.rep2_cell_cycle     ✓\n",
      "\n",
      "\n",
      "Confirm there aren't any weird rounding errors in 'start_position_Mb':\n",
      "chr21                     ✓\n",
      "chr21.rep1                ✓\n",
      "chr21.rep2_cell_cycle     ✓\n"
     ]
    }
   ],
   "source": [
    "# [GC+] Assess data structure\n",
    "in_common = False\n",
    "for name, data in all_data.items():\n",
    "    print(f'\\n======== {name} ========')\n",
    "    for key, val in data.items():\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            in_common = True\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "\n",
    "if in_common:\n",
    "    print(f'\\n======== BOTH REPS ========')\n",
    "    for key, val in data_rep1.items():\n",
    "        if not (key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key])):\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "            \n",
    "\n",
    "print(\"\\n\\nIs 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\")\n",
    "for name, data in all_data.items():\n",
    "    if 'chrom_ids' in data:\n",
    "        tmp = np.array_equal(data_rep1['chrom_ids'], np.arange(1, len(data_rep1['chrom_ids']) + 1))\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[tmp])\n",
    "\n",
    "print(\"\\n\\nConfirm there aren't any weird rounding errors in 'start_position_Mb':\")\n",
    "for name, data in all_data.items():\n",
    "    if 'start_position_Mb' in data:\n",
    "        tmp = (data['start_position_Mb'] - np.round(data['start_position_Mb'], 4)) != 0\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[~np.any(tmp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10400001 10500001 10600001 13250001 14000001 14050001 14100001 14150001\n",
      " 14200001 14250001]\n",
      "[10400000 10500000 10600000 13250000 14000000 14050000 14100000 14150000\n",
      " 14200000 14250000]\n",
      "[10.4  10.5  10.6  13.25 14.   14.05 14.1  14.15 14.2  14.25]\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05]\n"
     ]
    }
   ],
   "source": [
    "print((region_starts)[:10])\n",
    "print((region_starts - 1)[:10])\n",
    "print(((region_starts - 1)[:10].astype(int) / 10 ** 6))\n",
    "print(np.round((region_starts - 1)[:10].astype(int) / 10 ** 6, 4) % 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.chrom_ids.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.G1_flags.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.G2-S_flags.npy\n"
     ]
    }
   ],
   "source": [
    "# [GC+] SAVE in-progress files - numpy\n",
    "\n",
    "for name, data in all_data.items():\n",
    "    for key, val in data.items():\n",
    "        if len(val) == 0 or key in ('start_position_Mb', 'end_position_Mb') or np.array_equal(np.asarray(val).ravel(), np.arange(np.asarray(val).size) + 1):\n",
    "            continue\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            tmp = chrom\n",
    "        else:\n",
    "            tmp = name\n",
    "        if isinstance(val, dict):\n",
    "            pass\n",
    "        else:\n",
    "            key = key.replace('/', '-')\n",
    "            print(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"))\n",
    "            np.save(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GC+] SAVE in-progress files - pickled\n",
    "with open(os.path.join(dir_3d_coords, rep1) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, rep2) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, chrom) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_combined, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "\n",
    "# with open(rep1_coords_file, 'rb') as handle:\n",
    "#     data_rep1 = pickle.load(handle)\n",
    "# with open(rep2_coords_file, 'rb') as handle:\n",
    "#     data_rep2 = pickle.load(handle)\n",
    "\n",
    "# with open(combo_coords_file, 'rb') as handle:\n",
    "#     data_combined = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 generate imaging-based median distance and proximity frequency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import pdist, squareform\n",
    "# zxys_combined_list = np.array(data_combined['dna_zxys'])\n",
    "# distmap_combined_list = np.array([squareform(pdist(_zxy)) for _zxy in tqdm(zxys_combined_list)])\n",
    "\n",
    "# # generate median distance map\n",
    "# median_distance_map_combined = np.nanmedian(distmap_combined_list, axis = 0)\n",
    "# # generate contact map\n",
    "# contact_th = 500\n",
    "# contact_map_combined = np.sum(distmap_combined_list<contact_th, axis=0) / np.sum(np.isnan(distmap_combined_list)==False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f8419b994c4ab6b9415b50ace95fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd9572a92514ec09510e1ed5ca8fd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [GC+] edited so I can SAVE in-progress files\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "zxys_combined_list = np.array(data_combined['dna_zxys'])\n",
    "\n",
    "distmap_combined_list = np.concatenate([pdist(_zxy).reshape(1, -1) for _zxy in tqdm(zxys_combined_list)])\n",
    "np.save(distmap_list_file, distmap_combined_list) # [GC+] SAVE in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sc distances...\n",
      "chr21\n"
     ]
    }
   ],
   "source": [
    "chrom = 'chr21'\n",
    "distvec_per_cell = None\n",
    "print('Loading sc distances...'); distvec_per_cell = np.load(files_progress[chrom]['distances.per_cell'])\n",
    "print(chrom)\n",
    "process_sc_distances(files_progress[chrom], distvec_per_cell=distvec_per_cell, dis_mean=True, dis_median=True, contact_th=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "# distmap_combined_list = np.load(distmap_list_file)\n",
    "# median_distance_map_combined = np.load(median_distance_map_file)\n",
    "# contact_map_combined = np.load(median_distance_map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "# Chromosome 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.gc'></a>\n",
    "## 1.gc Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2\n",
      "chr2.rep1\n",
      "chr2.rep2_p_arm\n"
     ]
    }
   ],
   "source": [
    "chrom = 'chr2'\n",
    "rep1_filename = files_3dcoords[chrom]['rep1']\n",
    "rep2_filename = files_3dcoords[chrom]['rep2']\n",
    "rep1 = files_progress[chrom]['rep1']\n",
    "rep2 = files_progress[chrom]['rep2']\n",
    "print(chrom); print(rep1); print(rep2)\n",
    "\n",
    "dir_3d_coords =  files_progress[chrom]['dir_coords3d']\n",
    "distmap_list_file = files_progress[chrom]['distances.per_cell']\n",
    "median_distance_map_file = files_progress[chrom]['distances.median']\n",
    "mean_distance_map_file = files_progress[chrom]['distances.mean']\n",
    "contacts_mean_c500_file = files_progress[chrom]['contacts.mean.cutoff500']\n",
    "contacts_percell_c500_file = files_progress[chrom]['contacts.per_cell.cutoff500']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 1.1 load chr2 replicate 1 \n",
    "\n",
    "(entire chr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71554eb51e0d482e87db8e3b2d1f70df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep1_info_dict = {}\n",
    "with open(rep1_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep1_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep1_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep1 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep1_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep1_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep1_info_dict['Z(nm)'],rep1_info_dict['X(nm)'],\\\n",
    "                                         rep1_info_dict['Y(nm)'],rep1_info_dict['Genomic coordinate'],\\\n",
    "                                         rep1_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep1['chrom_ids'] = chr_ids\n",
    "data_rep1['region_names'] = region_names\n",
    "data_rep1['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep1['start_position_Mb'] = start_position_Mb\n",
    "data_rep1['end_position_Mb'] = end_position_Mb\n",
    "data_rep1['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep1_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep1_info_dict['Gene names'],\n",
    "                                                   rep1_info_dict['Transcription'],\n",
    "                                                   rep1_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep1_info_dict['Chromosome copy number'],\n",
    "                                                                  rep1_info_dict['Gene names'],\n",
    "                                                                  rep1_info_dict['Transcription'],\n",
    "                                                                  rep1_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep1['gene_names'] = gene_names\n",
    "    data_rep1['tss_zxys'] = tss_zxys_list\n",
    "    data_rep1['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep1_info_dict:\n",
    "    cell_cycle_types = np.unique(rep1_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep1_info_dict['Chromosome copy number'],rep1_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep1[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 1.2 load chr2 replicate 2 \n",
    "\n",
    "(p-arm only, first 357 regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab24d76d64304a42b56008b43ff92529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep2_info_dict = {}\n",
    "with open(rep2_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep2_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep2_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep2 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep2_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep2_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep2_info_dict['Z(nm)'],rep2_info_dict['X(nm)'],\\\n",
    "                                         rep2_info_dict['Y(nm)'],rep2_info_dict['Genomic coordinate'],\\\n",
    "                                         rep2_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep2['chrom_ids'] = chr_ids\n",
    "data_rep2['region_names'] = region_names\n",
    "data_rep2['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep2['start_position_Mb'] = start_position_Mb\n",
    "data_rep2['end_position_Mb'] = end_position_Mb\n",
    "data_rep2['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep2_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep2_info_dict['Gene names'],\n",
    "                                                   rep2_info_dict['Transcription'],\n",
    "                                                   rep2_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep2_info_dict['Chromosome copy number'],\n",
    "                                                                  rep2_info_dict['Gene names'],\n",
    "                                                                  rep2_info_dict['Transcription'],\n",
    "                                                                  rep2_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep2['gene_names'] = gene_names\n",
    "    data_rep2['tss_zxys'] = tss_zxys_list\n",
    "    data_rep2['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep2_info_dict:\n",
    "    cell_cycle_types = np.unique(rep2_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep2_info_dict['Chromosome copy number'],rep2_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep2[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Save current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {rep1: data_rep1, rep2: data_rep2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== chr2.rep1 ========\n",
      "chrom_ids            ndarray    (3029,)\n",
      "region_names         ndarray    (935,)\n",
      "mid_position_Mb      ndarray    (935,)\n",
      "start_position_Mb    ndarray    (935,)\n",
      "end_position_Mb      ndarray    (935,)\n",
      "dna_zxys             ndarray    (3029, 935, 3)\n",
      "\n",
      "======== chr2.rep2_p_arm ========\n",
      "chrom_ids            ndarray    (4848,)\n",
      "region_names         ndarray    (357,)\n",
      "mid_position_Mb      ndarray    (357,)\n",
      "start_position_Mb    ndarray    (357,)\n",
      "end_position_Mb      ndarray    (357,)\n",
      "dna_zxys             ndarray    (4848, 357, 3)\n",
      "\n",
      "======== BOTH REPS ========\n",
      "params               dict       0\n",
      "\n",
      "\n",
      "Is 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\n",
      "chr2.rep1           : True\n",
      "chr2.rep2_p_arm     : True\n",
      "\n",
      "\n",
      "Are there weird rounding errors in 'start_position_Mb'?\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# [GC+] Assess data structure\n",
    "in_common = False\n",
    "for name, data in all_data.items():\n",
    "    print(f'\\n======== {name} ========')\n",
    "    for key, val in data.items():\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            in_common = True\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "\n",
    "if in_common:\n",
    "    print(f'\\n======== BOTH REPS ========')\n",
    "    for key, val in data_rep1.items():\n",
    "        if not (key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key])):\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "            \n",
    "\n",
    "print(\"\\n\\nIs 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\")\n",
    "for name, data in all_data.items():\n",
    "    if 'chrom_ids' in data:\n",
    "        tmp = np.array_equal(data_rep1['chrom_ids'], np.arange(1, len(data_rep1['chrom_ids']) + 1))\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[tmp])\n",
    "\n",
    "print(\"\\n\\nConfirm there aren't any weird rounding errors in 'start_position_Mb':\")\n",
    "for name, data in all_data.items():\n",
    "    if 'start_position_Mb' in data:\n",
    "        tmp = (data['start_position_Mb'] - np.round(data['start_position_Mb'], 4)) != 0\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[~np.any(tmp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.dna_zxys.npy\n"
     ]
    }
   ],
   "source": [
    "# [GC+] SAVE in-progress files - numpy\n",
    "\n",
    "for name, data in all_data.items():\n",
    "    for key, val in data.items():\n",
    "        if len(val) == 0 or key in ('start_position_Mb', 'end_position_Mb') or np.array_equal(np.asarray(val).ravel(), np.arange(np.asarray(val).size) + 1):\n",
    "            continue\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            tmp = chrom\n",
    "        else:\n",
    "            tmp = name\n",
    "        if isinstance(val, dict):\n",
    "            pass\n",
    "        else:\n",
    "            key = key.replace('/', '-')\n",
    "            print(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"))\n",
    "            np.save(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GC+] SAVE in-progress files - pickled\n",
    "with open(os.path.join(dir_3d_coords, rep1) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, rep2) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "\n",
    "# with open(rep1_coords_file, 'rb') as handle:\n",
    "#     data_rep1 = pickle.load(handle)\n",
    "# with open(rep2_coords_file, 'rb') as handle:\n",
    "#     data_rep2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.0 corresponding regions for p and q arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # P and q arm crop\n",
    "# p_crop = slice(0, 357)\n",
    "# q_crop = slice(357, len(data_rep1['dna_zxys'][0]))\n",
    "# print(p_crop, q_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 generate imaging-based median distance and proximity frequency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import squareform, pdist\n",
    "# zxys_rep1_list = np.array(data_rep1['dna_zxys'])\n",
    "# distmap_rep1_list = np.array([squareform(pdist(_zxy)) for _zxy in zxys_rep1_list])\n",
    "# # calculate contact freq map\n",
    "# contact_th = 500\n",
    "# contact_rep1_map = np.sum(distmap_rep1_list<contact_th, axis=0) / np.sum(np.isnan(distmap_rep1_list)==False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69317f56bf404b67816c987021d07654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0968a5249b4849e5acdf5f7e19ae9cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [GC+] edited so I can SAVE in-progress files\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "zxys_rep1_list = np.array(data_rep1['dna_zxys'])\n",
    "\n",
    "distmap_rep1_list = np.concatenate([pdist(_zxy).reshape(1, -1) for _zxy in tqdm(zxys_rep1_list)])\n",
    "np.save(distmap_list_file, distmap_rep1_list) # [GC+] SAVE in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2\n",
      "Loading sc distances...\n"
     ]
    }
   ],
   "source": [
    "chrom = 'chr2'\n",
    "print(chrom)\n",
    "distvec_per_cell = None\n",
    "print('Loading sc distances...'); distvec_per_cell = np.load(files_progress[chrom]['distances.per_cell'])\n",
    "process_sc_distances(files_progress[chrom], distvec_per_cell=distvec_per_cell, dis_mean=True, dis_median=True, contact_th=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "# distmap_combined_list = np.load(distmap_list_file)\n",
    "# median_distance_map_combined = np.load(median_distance_map_file)\n",
    "# contact_map_combined = np.load(median_distance_map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create proper hiclib-style counts matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dir_coords3d', 'rep1', 'rep2', 'distances.per_cell', 'distances.median', 'distances.mean', 'contacts.cutoff500', 'proceed_with'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check, make sure all regions are 0.05 Mb\n",
    "for chrom in files_progress.keys():\n",
    "    region_names = np.load(os.path.join(files_progress[chrom]['dir_coords3d'], files_progress[chrom]['proceed_with'] + '.region_names.npy'))\n",
    "    regions = np.concatenate([np.array(re.split(r'[:-]', x)[1:], dtype=int).reshape(1, -1) for x in region_names])\n",
    "    region_sizes = np.unique(regions[:,1] - regions[:,0]) / 1e6\n",
    "    if region_sizes.size != 1 or region_sizes[0] != 0.05:\n",
    "        raise ValueError('Region sizes not all equal to 0.05 Mb')\n",
    "        \n",
    "files_progress[chrom].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check, make sure there aren't any beads that are NaN on one axis but not all axes\n",
    "for chrom in files_progress.keys():\n",
    "    dna_zxys = np.load(os.path.join(files_progress[chrom]['dir_coords3d'], files_progress[chrom]['proceed_with'] + '.dna_zxys.npy'))\n",
    "    tmp = np.isnan(dna_zxys).sum(2) \n",
    "    irregular_nans = np.sum((tmp != 0) & (tmp != 3))\n",
    "    if irregular_nans != 0:\n",
    "        raise ValueError('Some beads have NaNs one one axis but not all axes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', message='', category=UserWarning)\n",
    "    warnings.filterwarnings('ignore', message='', category=FutureWarning)\n",
    "    from iced.io import write_counts, write_lengths\n",
    "\n",
    "def get_complete_counts_matrix(files_progress, chrom, good_locus_th=0.75, good_cell_th=0.9, res=0.05, verbose=False, load_counts=True, save_counts=False):\n",
    "    # Load data... shape=(ncells, nbins, 3)\n",
    "    dna_zxys = np.load(os.path.join(files_progress[chrom]['dir_coords3d'], files_progress[chrom]['proceed_with'] + '.dna_zxys.npy'))\n",
    "    ncells_orig = dna_zxys.shape[0]\n",
    "    nbins_orig = dna_zxys.shape[1]\n",
    "    \n",
    "    # Ignore cells that have < good_cell_th*100% NaNs\n",
    "    cells_good = np.mean(~np.isnan(dna_zxys[:, :, 0]), axis=1) >= good_cell_th # Ratio of good-bins-per-cell >= good_cell_th \n",
    "    perc_cells_discarded = (1 - np.mean(cells_good)) * 100\n",
    "    dna_zxys = dna_zxys[cells_good, :, :] # Filter out 'bad cells'\n",
    "    \n",
    "    # Ignore bins that are NaN < good_locus_th*100% \n",
    "    success_rates = np.mean(~np.isnan(dna_zxys[:, :, 0]), axis=0)\n",
    "    good_regions = np.where(success_rates >= good_locus_th)[0]\n",
    "    perc_regions_discarded = (1 - np.mean(success_rates >= good_locus_th)) * 100\n",
    "\n",
    "    # Get mids that pass cutoff\n",
    "    mids_orig = np.load(os.path.join(files_progress[chrom]['dir_coords3d'], files_progress[chrom]['proceed_with'] + '.mid_position_Mb.npy'))\n",
    "    if not np.array_equal(mids_orig, np.sort(mids_orig)):\n",
    "        raise ValueError('Midpoints not in ascending order')\n",
    "    mids_good = mids_orig[good_regions]\n",
    "    \n",
    "    # Compute coverage\n",
    "    mids_all = np.round(np.arange(mids_good.min(), mids_good.max() + res, res), 6)\n",
    "    coverage = mids_good.size / mids_all.size * 100\n",
    "    idx = np.where(np.isin(mids_all, mids_good))[0]\n",
    "    mids_all_untrunc = np.round(np.arange(mids_orig.min(), mids_orig.max() + res, res), 6)\n",
    "    coverage_untrunc = mids_good.size / mids_all_untrunc.size * 100\n",
    "    idx_untrunc = np.where(np.isin(mids_all_untrunc, mids_good))[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Chrom={chrom.ljust(9)} CellTh={str(good_cell_th).ljust(7)} LocusTh={str(good_locus_th).ljust(7)} Cov={coverage:.1f}%   CovUntrunc={coverage_untrunc:.1f}%\")\n",
    "        \n",
    "    res = {'chrom': chrom, 'good_locus_th': good_locus_th, 'good_cell_th': good_cell_th,\n",
    "           'coverage': coverage, 'coverage_untrunc': coverage_untrunc,\n",
    "           'perc_cells_discarded': perc_cells_discarded, 'perc_regions_discarded': perc_regions_discarded, 'ncells': ncells_orig, 'nbins': nbins_orig}\n",
    "        \n",
    "    if load_counts:\n",
    "        # Get counts that pass cutoff\n",
    "        counts_orig = np.triu(np.load(os.path.join(files_progress[chrom]['contacts.mean.cutoff500'])), 1)\n",
    "        counts_good = counts_orig[good_regions][:,good_regions]\n",
    "        \n",
    "        res['nreads_total'] = counts_good.sum() # FIXME - not correct if good_cell_th>0\n",
    "        res['nreads_perbin'] = counts_good[np.triu_indices(counts_good.shape[0], 1)].mean() # FIXME - not correct if good_cell_th>0\n",
    "\n",
    "        # Create complete counts matrix\n",
    "        counts = np.zeros((mids_all.size, mids_all.size), dtype=int)\n",
    "        counts[idx][:,idx] = counts_good\n",
    "        \n",
    "        # counts_good_nan = (counts_good.sum(axis=0).ravel() == 0) & (counts_good.sum(axis=1).ravel() == 0)\n",
    "        # print(counts_good_nan.sum())\n",
    "        #print(f\"SHAPE: dna_zxys={dna_zxys.shape[1]}, mids_orig={mids_orig.size}, mids_good={mids_good.size}, mids_all={mids_all.size}, counts_orig={counts_orig.shape}, mids_all_untrunc={mids_all_untrunc.size}\")\n",
    "        \n",
    "        if save_counts:\n",
    "            outdir = os.path.join(counts_folder, f\"{chrom}.cutoff{good_locus_th}\")\n",
    "            write_counts(os.path.join(outdir, \"counts.matrix\"), counts)\n",
    "            write_lengths(os.path.join(outdir, \"counts.bed\"), np.array([counts.shape[0]]))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_complete_counts_matrix(files_progress, chrom='chr21', good_cell_th=0, good_locus_th=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_good_cell_th = (0, 0.9, 0.99, 0.999)\n",
    "list_good_locus_th = (0, 0.75, 0.8, 0.9, 0.95, 0.975, 0.98)\n",
    "\n",
    "list_good_cell_th = (0.99, 0.999)\n",
    "list_good_locus_th = (0.99,)\n",
    "\n",
    "# list_good_cell_th = (0,)\n",
    "# list_good_locus_th = (0,)\n",
    "\n",
    "df = []\n",
    "for chrom in files_progress.keys():\n",
    "    for good_cell_th in list_good_cell_th:\n",
    "        #print(f\"\\n=== good_cell_th={good_cell_th}\")\n",
    "        for good_locus_th in list_good_locus_th:\n",
    "            res = get_complete_counts_matrix(files_progress, chrom=chrom, good_cell_th=good_cell_th, good_locus_th=good_locus_th, verbose=False)\n",
    "            df.append(res)\n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>good_locus_th</th>\n",
       "      <th>good_cell_th</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coverage_untrunc</th>\n",
       "      <th>perc_cells_discarded</th>\n",
       "      <th>perc_regions_discarded</th>\n",
       "      <th>ncells</th>\n",
       "      <th>nbins</th>\n",
       "      <th>nreads_total</th>\n",
       "      <th>nreads_perbin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr21</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.990</td>\n",
       "      <td>88.639761</td>\n",
       "      <td>81.680441</td>\n",
       "      <td>82.895712</td>\n",
       "      <td>8.90937</td>\n",
       "      <td>12149</td>\n",
       "      <td>651</td>\n",
       "      <td>23600.730551</td>\n",
       "      <td>0.134456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr21</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.999</td>\n",
       "      <td>89.669421</td>\n",
       "      <td>89.669421</td>\n",
       "      <td>98.617170</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12149</td>\n",
       "      <td>651</td>\n",
       "      <td>28191.154977</td>\n",
       "      <td>0.133244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.990</td>\n",
       "      <td>19.314191</td>\n",
       "      <td>19.314191</td>\n",
       "      <td>3.202377</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3029</td>\n",
       "      <td>935</td>\n",
       "      <td>16843.182788</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.999</td>\n",
       "      <td>19.314191</td>\n",
       "      <td>19.314191</td>\n",
       "      <td>13.040607</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3029</td>\n",
       "      <td>935</td>\n",
       "      <td>16843.182788</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom  good_locus_th  good_cell_th   coverage  coverage_untrunc  \\\n",
       "0  chr21           0.99         0.990  88.639761         81.680441   \n",
       "1  chr21           0.99         0.999  89.669421         89.669421   \n",
       "2   chr2           0.99         0.990  19.314191         19.314191   \n",
       "3   chr2           0.99         0.999  19.314191         19.314191   \n",
       "\n",
       "   perc_cells_discarded  perc_regions_discarded  ncells  nbins  nreads_total  \\\n",
       "0             82.895712                 8.90937   12149    651  23600.730551   \n",
       "1             98.617170                 0.00000   12149    651  28191.154977   \n",
       "2              3.202377                 0.00000    3029    935  16843.182788   \n",
       "3             13.040607                 0.00000    3029    935  16843.182788   \n",
       "\n",
       "   nreads_perbin  \n",
       "0       0.134456  \n",
       "1       0.133244  \n",
       "2       0.038574  \n",
       "3       0.038574  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = 'chr2'\n",
    "res = 0.05\n",
    "\n",
    "mids_orig = np.load(os.path.join(files_progress[chrom]['dir_coords3d'], files_progress[chrom]['proceed_with'] + '.mid_position_Mb.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = (np.round(mids_orig * 1e3)).astype(int)\n",
    "to_next_bin = ((foo[1:] - foo[:-1]) / int(res * 1e3)).astype(int)\n",
    "# gaps_mask = np.where(to_next_bin != 250)[0]\n",
    "# print(np.stack([gaps_mask, to_next_bin[gaps_mask]], axis=1))\n",
    "# # print(to_next_bin[gaps_mask])\n",
    "\n",
    "print((foo[1:] - foo[:-1]).min() / int(res * 1e3))\n",
    "(foo[1:] - foo[:-1]).min(), int(res * 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 10.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5., 10.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5., 10.,  5., 10.,  5.,  5.,  5.,\n",
       "        5., 15.,  5., 35., 60.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5., 15.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 25.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 10.,  5.,\n",
       "       10.,  5.,  5., 10.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 10.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5., 10.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_next_bin = ((mids_orig[1:] - mids_orig[:-1]) / res)\n",
    "# gaps_mask = np.where(to_next_bin != 250)[0]\n",
    "# print(np.stack([gaps_mask, to_next_bin[gaps_mask]], axis=1))\n",
    "# # print(to_next_bin[gaps_mask])\n",
    "\n",
    "# print((foo[1:] - foo[:-1]).min() / int(res *e3))\n",
    "# (foo[1:] - foo[:-1]).min(), int(res * 1e3)\n",
    "\n",
    "to_next_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.025],\n",
       "       [0.275],\n",
       "       [0.525],\n",
       "       [0.775],\n",
       "       [1.025],\n",
       "       [1.275],\n",
       "       [1.525],\n",
       "       [1.775],\n",
       "       [2.025],\n",
       "       [2.275]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mids_good = mids_orig\n",
    "mids_all = np.round(np.arange(mids_good.min(), mids_good.max() + res, res), 6)\n",
    "gaps_mask, mids_all.shape, mids_good.shape\n",
    "\n",
    "\n",
    "# # P and q arm crop\n",
    "# p_crop = slice(0, 357)\n",
    "# q_crop = slice(357, len(data_rep1['dna_zxys'][0]))\n",
    "# print(p_crop, q_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 10, None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
