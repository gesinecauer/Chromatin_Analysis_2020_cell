{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='0'></a>\n",
    "# 0. Minimum required packages and settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='0.1'></a>\n",
    "## 0.1 import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430539\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(r\"..\", r\".\")))\n",
    "\n",
    "import source as ia\n",
    "\n",
    "print(os.getpid()) # print this so u can terminate through cmd / task-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='0.2'></a>\n",
    "## 0.2 parameters for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting setting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', serif='Arial')\n",
    "_font_size = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plotting parameters\n",
    "from source.figure_tools import _dpi,_single_col_width,_double_col_width,_single_row_height,_ref_bar_length, _ticklabel_size,_ticklabel_width,_font_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder: /net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/zenodo_dl\n"
     ]
    }
   ],
   "source": [
    "# please change data_folder into the folder for downloaded dataset\n",
    "data_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"zenodo_dl\"))\n",
    "print(f\"data_folder: {data_folder}\")\n",
    "\n",
    "# # figure folder\n",
    "# # please specify location to save images\n",
    "# results_folder = os.path.abspath(os.path.join(r\"..\", r\"results\"))\n",
    "# parent_figure_folder = os.path.abspath(os.path.join(results_folder, \"figures\"))\n",
    "# os.makedirs(results_folder, exist_ok=True)\n",
    "# os.makedirs(parent_figure_folder, exist_ok=True)\n",
    "# print(f\"results_folder: {results_folder}\")\n",
    "# print(f\"parent_figure_folder: {parent_figure_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please visit zenodo with DOI:10.5281/zenodo.3928890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "# Chromosome 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.gc'></a>\n",
    "## 1.gc Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr21.rep1\n",
      "chr21.rep2_cell_cycle\n",
      "chr21\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# please update as needed\n",
    "rep1_filename = os.path.join(data_folder, 'chrom_trace',  'chr21.rep1.tsv')\n",
    "rep2_filename = os.path.join(data_folder, 'chrom_trace', 'chr21.rep2_cell_cycle.tsv')\n",
    "\n",
    "# Replicates & chromosome\n",
    "rep1 = os.path.basename(rep1_filename).replace('.tsv', '')\n",
    "rep2 = os.path.basename(rep2_filename).replace('.tsv', '')\n",
    "chrom = re.sub(r'^(chr[a-z]*[1-9][0-9]*).*', r'\\1', os.path.commonprefix([rep1, rep2]))\n",
    "print(rep1), print(rep2), print(chrom)\n",
    "\n",
    "# [GC+] For saving partial progress\n",
    "progress_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"in_progress\"))\n",
    "os.makedirs(progress_folder, exist_ok=True)\n",
    "\n",
    "# [GC+] For saving partial progress: 3D COORDS\n",
    "dir_3d_coords = os.path.join(progress_folder, '3d_coords', chrom)\n",
    "os.makedirs(dir_3d_coords, exist_ok=True)\n",
    "\n",
    "# [GC+] For saving partial progress: DISTANCES\n",
    "os.makedirs(os.path.join(progress_folder, 'distances'), exist_ok=True)\n",
    "distmap_list_file = os.path.join(progress_folder, 'distances', f'{chrom}.distances.per_cell.npy')\n",
    "median_distance_map_file = os.path.join(progress_folder, 'distances', f'{chrom}.distances.median.npy')\n",
    "median_distance_map_file = os.path.join(progress_folder, 'distances', f'{chrom}.contacts.cutoff500.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 1.1 load chr21 replicate 1 \n",
    "\n",
    "(without cell cycle information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number', 'Gene names', 'Transcription', 'TSS ZXY(nm)']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3982c46d7dd04012bdfcd745313f45eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 genes exist in this dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4972ffbf8f6a4712aa02423f2e2b0f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/gs/vol1/home/gesine/local/anaconda3/envs/su2020/lib/python3.7/site-packages/ipykernel_launcher.py:101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep1_info_dict = {}\n",
    "with open(rep1_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep1_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep1_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep1 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep1_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep1_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep1_info_dict['Z(nm)'],rep1_info_dict['X(nm)'],\\\n",
    "                                         rep1_info_dict['Y(nm)'],rep1_info_dict['Genomic coordinate'],\\\n",
    "                                         rep1_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep1['chrom_ids'] = chr_ids\n",
    "data_rep1['region_names'] = region_names\n",
    "data_rep1['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep1['start_position_Mb'] = start_position_Mb\n",
    "data_rep1['end_position_Mb'] = end_position_Mb\n",
    "data_rep1['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep1_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep1_info_dict['Gene names'],\n",
    "                                                   rep1_info_dict['Transcription'],\n",
    "                                                   rep1_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep1_info_dict['Chromosome copy number'],\n",
    "                                                                  rep1_info_dict['Gene names'],\n",
    "                                                                  rep1_info_dict['Transcription'],\n",
    "                                                                  rep1_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep1['gene_names'] = gene_names\n",
    "    data_rep1['tss_zxys'] = tss_zxys_list\n",
    "    data_rep1['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep1_info_dict:\n",
    "    cell_cycle_types = np.unique(rep1_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep1_info_dict['Chromosome copy number'],rep1_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep1[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 1.2 load chr21 replicate 2 \n",
    "\n",
    "(with cell cycle information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number', 'Gene names', 'Transcription', 'TSS ZXY(nm)', 'Cell cycle state']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f2af26b3aa422598fb70cf94f27336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 genes exist in this dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c1e18321c0460a86fc4dcb70bc00bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/gs/vol1/home/gesine/local/anaconda3/envs/su2020/lib/python3.7/site-packages/ipykernel_launcher.py:101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a011cb0ff2874886a7c7c548f0ec5244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep2_info_dict = {}\n",
    "with open(rep2_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep2_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep2_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep2 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep2_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep2_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep2_info_dict['Z(nm)'],rep2_info_dict['X(nm)'],\\\n",
    "                                         rep2_info_dict['Y(nm)'],rep2_info_dict['Genomic coordinate'],\\\n",
    "                                         rep2_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep2['chrom_ids'] = chr_ids\n",
    "data_rep2['region_names'] = region_names\n",
    "data_rep2['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep2['start_position_Mb'] = start_position_Mb\n",
    "data_rep2['end_position_Mb'] = end_position_Mb\n",
    "data_rep2['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep2_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep2_info_dict['Gene names'],\n",
    "                                                   rep2_info_dict['Transcription'],\n",
    "                                                   rep2_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep2_info_dict['Chromosome copy number'],\n",
    "                                                                  rep2_info_dict['Gene names'],\n",
    "                                                                  rep2_info_dict['Transcription'],\n",
    "                                                                  rep2_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep2['gene_names'] = gene_names\n",
    "    data_rep2['tss_zxys'] = tss_zxys_list\n",
    "    data_rep2['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep2_info_dict:\n",
    "    cell_cycle_types = np.unique(rep2_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep2_info_dict['Chromosome copy number'],rep2_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep2[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.3 combine two datasets\n",
    "\n",
    "in most of panels we combined chromosomes from two replicates for better statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chromosomes: 12149\n"
     ]
    }
   ],
   "source": [
    "data_combined = {}\n",
    "for _k in data_rep1:\n",
    "    if _k in data_rep2:\n",
    "        # concatenate if this is some chromosomal data\n",
    "        if len(data_rep1[_k]) == len(data_rep1[\"chrom_ids\"]):\n",
    "            data_combined[_k] = np.concatenate([data_rep1[_k],data_rep2[_k]])\n",
    "        # directly merge if this is some shared information\n",
    "        elif (np.array(data_rep1[_k]) == np.array(data_rep2[_k])).all():\n",
    "            data_combined[_k] = data_rep1[_k]\n",
    "            \n",
    "print('Number of chromosomes:', len(data_combined['chrom_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Save current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {chrom: data_combined, rep1: data_rep1, rep2: data_rep2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== chr21 ========\n",
      "chrom_ids            ndarray    (12149,)\n",
      "dna_zxys             ndarray    (12149, 651, 3)\n",
      "tss_zxys             ndarray    (12149, 84, 3)\n",
      "trans_pfs            ndarray    (12149, 84)\n",
      "\n",
      "======== chr21.rep1 ========\n",
      "chrom_ids            ndarray    (7591,)\n",
      "dna_zxys             ndarray    (7591, 651, 3)\n",
      "tss_zxys             ndarray    (7591, 84, 3)\n",
      "trans_pfs            ndarray    (7591, 84)\n",
      "\n",
      "======== chr21.rep2_cell_cycle ========\n",
      "chrom_ids            ndarray    (4558,)\n",
      "dna_zxys             ndarray    (4558, 651, 3)\n",
      "tss_zxys             ndarray    (4558, 84, 3)\n",
      "trans_pfs            ndarray    (4558, 84)\n",
      "G1_flags             ndarray    (4558,)\n",
      "G2/S_flags           ndarray    (4558,)\n",
      "\n",
      "======== BOTH REPS ========\n",
      "params               dict       0\n",
      "region_names         ndarray    (651,)\n",
      "mid_position_Mb      ndarray    (651,)\n",
      "start_position_Mb    ndarray    (651,)\n",
      "end_position_Mb      ndarray    (651,)\n",
      "gene_names           list       84\n",
      "\n",
      "\n",
      "Is 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\n",
      "chr21                     ✓\n",
      "chr21.rep1                ✓\n",
      "chr21.rep2_cell_cycle     ✓\n",
      "\n",
      "\n",
      "Confirm there aren't any weird rounding errors in 'start_position_Mb':\n",
      "chr21                     ✓\n",
      "chr21.rep1                ✓\n",
      "chr21.rep2_cell_cycle     ✓\n"
     ]
    }
   ],
   "source": [
    "# [GC+] Assess data structure\n",
    "in_common = False\n",
    "for name, data in all_data.items():\n",
    "    print(f'\\n======== {name} ========')\n",
    "    for key, val in data.items():\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            in_common = True\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "\n",
    "if in_common:\n",
    "    print(f'\\n======== BOTH REPS ========')\n",
    "    for key, val in data_rep1.items():\n",
    "        if not (key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key])):\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "            \n",
    "\n",
    "print(\"\\n\\nIs 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\")\n",
    "for name, data in all_data.items():\n",
    "    if 'chrom_ids' in data:\n",
    "        tmp = np.array_equal(data_rep1['chrom_ids'], np.arange(1, len(data_rep1['chrom_ids']) + 1))\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[tmp])\n",
    "\n",
    "print(\"\\n\\nConfirm there aren't any weird rounding errors in 'start_position_Mb':\")\n",
    "for name, data in all_data.items():\n",
    "    if 'start_position_Mb' in data:\n",
    "        tmp = (data['start_position_Mb'] - np.round(data['start_position_Mb'], 4)) != 0\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[~np.any(tmp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10400001 10500001 10600001 13250001 14000001 14050001 14100001 14150001\n",
      " 14200001 14250001]\n",
      "[10400000 10500000 10600000 13250000 14000000 14050000 14100000 14150000\n",
      " 14200000 14250000]\n",
      "[10.4  10.5  10.6  13.25 14.   14.05 14.1  14.15 14.2  14.25]\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05]\n"
     ]
    }
   ],
   "source": [
    "print((region_starts)[:10])\n",
    "print((region_starts - 1)[:10])\n",
    "print(((region_starts - 1)[:10].astype(int) / 10 ** 6))\n",
    "print(np.round((region_starts - 1)[:10].astype(int) / 10 ** 6, 4) % 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.chrom_ids.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep1.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.gene_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.tss_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.trans_pfs.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.G1_flags.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr21/chr21.rep2_cell_cycle.G2-S_flags.npy\n"
     ]
    }
   ],
   "source": [
    "# [GC+] SAVE in-progress files - numpy\n",
    "\n",
    "for name, data in all_data.items():\n",
    "    for key, val in data.items():\n",
    "        if len(val) == 0 or key in ('start_position_Mb', 'end_position_Mb') or np.array_equal(np.asarray(val).ravel(), np.arange(np.asarray(val).size) + 1):\n",
    "            continue\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            tmp = chrom\n",
    "        else:\n",
    "            tmp = name\n",
    "        if isinstance(val, dict):\n",
    "            pass\n",
    "        else:\n",
    "            key = key.replace('/', '-')\n",
    "            print(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"))\n",
    "            np.save(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GC+] SAVE in-progress files - pickled\n",
    "with open(os.path.join(dir_3d_coords, rep1) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, rep2) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, chrom) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_combined, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "\n",
    "# with open(rep1_coords_file, 'rb') as handle:\n",
    "#     data_rep1 = pickle.load(handle)\n",
    "# with open(rep2_coords_file, 'rb') as handle:\n",
    "#     data_rep2 = pickle.load(handle)\n",
    "\n",
    "# with open(combo_coords_file, 'rb') as handle:\n",
    "#     data_combined = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 generate imaging-based median distance and proximity frequency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import pdist, squareform\n",
    "# zxys_combined_list = np.array(data_combined['dna_zxys'])\n",
    "# distmap_combined_list = np.array([squareform(pdist(_zxy)) for _zxy in tqdm(zxys_combined_list)])\n",
    "\n",
    "# # generate median distance map\n",
    "# median_distance_map_combined = np.nanmedian(distmap_combined_list, axis = 0)\n",
    "# # generate contact map\n",
    "# contact_th = 500\n",
    "# contact_map_combined = np.sum(distmap_combined_list<contact_th, axis=0) / np.sum(np.isnan(distmap_combined_list)==False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f8419b994c4ab6b9415b50ace95fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd9572a92514ec09510e1ed5ca8fd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [GC+] edited so I can SAVE in-progress files\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "zxys_combined_list = np.array(data_combined['dna_zxys'])\n",
    "\n",
    "distmap_combined_list = np.concatenate([pdist(_zxy).reshape(1, -1) for _zxy in tqdm(zxys_combined_list)])\n",
    "np.save(distmap_list_file, distmap_combined_list) # [GC+] SAVE in-progress files\n",
    "\n",
    "distmap_combined_list = np.array([squareform(distvec) for distvec in tqdm(distmap_combined_list)])\n",
    "\n",
    "# generate median distance map\n",
    "median_distance_map_combined = np.nanmedian(distmap_combined_list, axis = 0)\n",
    "np.save(median_distance_map_file, median_distance_map_combined) # [GC+] SAVE in-progress files\n",
    "\n",
    "# generate contact map\n",
    "contact_th = 500\n",
    "contact_map_combined = np.sum(distmap_combined_list<contact_th, axis=0) / np.sum(np.isnan(distmap_combined_list)==False, axis=0)\n",
    "np.save(median_distance_map_file, contact_map_combined) # [GC+] SAVE in-progress files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "# distmap_combined_list = np.load(distmap_list_file)\n",
    "# median_distance_map_combined = np.load(median_distance_map_file)\n",
    "# contact_map_combined = np.load(median_distance_map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "# Chromosome 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.gc'></a>\n",
    "## 1.gc Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2.rep1\n",
      "chr2.rep2_p_arm\n",
      "chr2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# please update as needed\n",
    "rep1_filename = os.path.join(data_folder, 'chrom_trace',  'chr2.rep1.tsv')\n",
    "rep2_filename = os.path.join(data_folder, 'chrom_trace', 'chr2.rep2_p_arm.tsv')\n",
    "\n",
    "# Replicates & chromosome\n",
    "rep1 = os.path.basename(rep1_filename).replace('.tsv', '')\n",
    "rep2 = os.path.basename(rep2_filename).replace('.tsv', '')\n",
    "chrom = re.sub(r'^(chr[a-z]*[1-9][0-9]*).*', r'\\1', os.path.commonprefix([rep1, rep2]))\n",
    "print(rep1), print(rep2), print(chrom)\n",
    "\n",
    "# [GC+] For saving partial progress\n",
    "progress_folder = os.path.abspath(os.path.join(r\"..\", r\"data\", r\"in_progress\"))\n",
    "os.makedirs(progress_folder, exist_ok=True)\n",
    "\n",
    "# [GC+] For saving partial progress: 3D COORDS\n",
    "dir_3d_coords = os.path.join(progress_folder, '3d_coords', chrom)\n",
    "os.makedirs(dir_3d_coords, exist_ok=True)\n",
    "\n",
    "# [GC+] For saving partial progress: DISTANCES\n",
    "os.makedirs(os.path.join(progress_folder, 'distances'), exist_ok=True)\n",
    "distmap_list_file = os.path.join(progress_folder, 'distances', f'{chrom}.distances.per_cell.npy')\n",
    "median_distance_map_file = os.path.join(progress_folder, 'distances', f'{chrom}.distances.median.npy')\n",
    "median_distance_map_file = os.path.join(progress_folder, 'distances', f'{chrom}.contacts.cutoff500.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 1.1 load chr2 replicate 1 \n",
    "\n",
    "(entire chr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71554eb51e0d482e87db8e3b2d1f70df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep1_info_dict = {}\n",
    "with open(rep1_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep1_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep1_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep1 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep1_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep1_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep1_info_dict['Z(nm)'],rep1_info_dict['X(nm)'],\\\n",
    "                                         rep1_info_dict['Y(nm)'],rep1_info_dict['Genomic coordinate'],\\\n",
    "                                         rep1_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep1['chrom_ids'] = chr_ids\n",
    "data_rep1['region_names'] = region_names\n",
    "data_rep1['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep1['start_position_Mb'] = start_position_Mb\n",
    "data_rep1['end_position_Mb'] = end_position_Mb\n",
    "data_rep1['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep1_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep1_info_dict['Gene names'],\n",
    "                                                   rep1_info_dict['Transcription'],\n",
    "                                                   rep1_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep1_info_dict['Chromosome copy number'],\n",
    "                                                                  rep1_info_dict['Gene names'],\n",
    "                                                                  rep1_info_dict['Transcription'],\n",
    "                                                                  rep1_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep1['gene_names'] = gene_names\n",
    "    data_rep1['tss_zxys'] = tss_zxys_list\n",
    "    data_rep1['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep1_info_dict:\n",
    "    cell_cycle_types = np.unique(rep1_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep1_info_dict['Chromosome copy number'],rep1_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep1[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## 1.2 load chr2 replicate 2 \n",
    "\n",
    "(p-arm only, first 357 regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z(nm)', 'X(nm)', 'Y(nm)', 'Genomic coordinate', 'Chromosome copy number']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab24d76d64304a42b56008b43ff92529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from file and extract info\n",
    "import csv\n",
    "rep2_info_dict = {}\n",
    "with open(rep2_filename, 'r') as _handle:\n",
    "    _reader = csv.reader(_handle, delimiter='\\t', quotechar='|')\n",
    "    _headers = next(_reader)\n",
    "    print(_headers)\n",
    "    # create keys for each header\n",
    "    for _h in _headers:\n",
    "        rep2_info_dict[_h] = []\n",
    "    # loop through content\n",
    "    for _contents in _reader:\n",
    "        for _h, _info in zip(_headers,_contents):\n",
    "            rep2_info_dict[_h].append(_info)\n",
    "\n",
    "# clean up information\n",
    "data_rep2 = {'params':{}}\n",
    "\n",
    "# clean up genomic coordiantes\n",
    "region_names = np.array([_n for _n in sorted(np.unique(rep2_info_dict['Genomic coordinate']), \n",
    "                                             key=lambda s:int(s.split(':')[1].split('-')[0]))])\n",
    "region_starts = np.array([int(_n.split(':')[1].split('-')[0]) for _n in region_names])\n",
    "region_ends = np.array([int(_n.split(':')[1].split('-')[1]) for _n in region_names])[np.argsort(region_starts)]\n",
    "region_starts = np.sort(region_starts)\n",
    "\n",
    "mid_positions = ((region_starts + region_ends)/2).astype(int)\n",
    "mid_positions_Mb = np.round(mid_positions / 1e6, 5) \n",
    "start_position_Mb = np.round(region_starts / 1e6, 5) \n",
    "end_position_Mb = np.round(region_ends / 1e6, 5) \n",
    "\n",
    "# clean up chrom copy number\n",
    "chr_nums = np.array([int(_info) for _info in rep2_info_dict['Chromosome copy number']])\n",
    "chr_ids, region_cts = np.unique(chr_nums, return_counts=True)\n",
    "dna_zxys_list = [[[] for _start in region_starts] for _id in chr_ids]\n",
    "\n",
    "# clean up zxy\n",
    "for _z,_x,_y,_reg_info, _cid in tqdm(zip(rep2_info_dict['Z(nm)'],rep2_info_dict['X(nm)'],\\\n",
    "                                         rep2_info_dict['Y(nm)'],rep2_info_dict['Genomic coordinate'],\\\n",
    "                                         rep2_info_dict['Chromosome copy number'])):\n",
    "    # get chromosome inds\n",
    "    _cid = int(_cid)\n",
    "    _cind = np.where(chr_ids == _cid)[0][0]\n",
    "    \n",
    "    # get region indices\n",
    "    _start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "    _rind = np.where(region_starts==_start)[0][0]\n",
    "    \n",
    "    dna_zxys_list[_cind][_rind] = np.array([float(_z),float(_x), float(_y)])\n",
    "\n",
    "# merge together\n",
    "dna_zxys_list = np.array(dna_zxys_list)\n",
    "data_rep2['chrom_ids'] = chr_ids\n",
    "data_rep2['region_names'] = region_names\n",
    "data_rep2['mid_position_Mb'] = mid_positions_Mb\n",
    "data_rep2['start_position_Mb'] = start_position_Mb\n",
    "data_rep2['end_position_Mb'] = end_position_Mb\n",
    "data_rep2['dna_zxys'] = dna_zxys_list\n",
    "\n",
    "# clean up tss and transcription\n",
    "if 'Gene names' in rep2_info_dict:\n",
    "    import re\n",
    "    # first extract number of genes\n",
    "    gene_names = []\n",
    "    for _gene_info, _trans_info, _tss_coord in zip(rep2_info_dict['Gene names'],\n",
    "                                                   rep2_info_dict['Transcription'],\n",
    "                                                   rep2_info_dict['TSS ZXY(nm)']):\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            for _gene in _genes:\n",
    "                if _gene not in gene_names:\n",
    "                    gene_names.append(_gene)\n",
    "    print(f\"{len(gene_names)} genes exist in this dataset.\")\n",
    "    \n",
    "    # initialize gene and transcription\n",
    "    tss_zxys_list = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    transcription_profiles = [[[] for _gene in gene_names] for _id in chr_ids]\n",
    "    # loop through to get info\n",
    "    for _cid, _gene_info, _trans_info, _tss_locations in tqdm(zip(rep2_info_dict['Chromosome copy number'],\n",
    "                                                                  rep2_info_dict['Gene names'],\n",
    "                                                                  rep2_info_dict['Transcription'],\n",
    "                                                                  rep2_info_dict['TSS ZXY(nm)'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        # process if there are genes in this region:\n",
    "        if _gene_info != '':\n",
    "            # split by semicolon\n",
    "            _genes = _gene_info.split(';')[:-1]\n",
    "            _transcribes = _trans_info.split(';')[:-1]\n",
    "            _tss_zxys = _tss_locations.split(';')[:-1]\n",
    "            for _gene, _transcribe, _tss_zxy in zip(_genes, _transcribes, _tss_zxys):\n",
    "                # get gene index\n",
    "                _gind = gene_names.index(_gene)\n",
    "                # get transcription profile\n",
    "                if _transcribe == 'on':\n",
    "                    transcription_profiles[_cind][_gind] = True\n",
    "                else:\n",
    "                    transcription_profiles[_cind][_gind] = False\n",
    "                # get coordinates\n",
    "                _tss_zxy = np.array([np.float(_c) for _c in re.split(r'\\s+', _tss_zxy.split('[')[1].split(']')[0]) if _c != ''])\n",
    "                tss_zxys_list[_cind][_gind] = _tss_zxy\n",
    "                \n",
    "    tss_zxys_list = np.array(tss_zxys_list)\n",
    "    transcription_profiles = np.array(transcription_profiles)\n",
    "    data_rep2['gene_names'] = gene_names\n",
    "    data_rep2['tss_zxys'] = tss_zxys_list\n",
    "    data_rep2['trans_pfs'] = transcription_profiles\n",
    "\n",
    "# clean up cell_cycle states\n",
    "if 'Cell cycle state' in rep2_info_dict:\n",
    "    cell_cycle_types = np.unique(rep2_info_dict['Cell cycle state'])\n",
    "    cell_cycle_flag_dict = {_k:[[] for _id in chr_ids] for _k in cell_cycle_types if _k != 'ND'}\n",
    "    for _cid, _state in tqdm(zip(rep2_info_dict['Chromosome copy number'],rep2_info_dict['Cell cycle state'])):\n",
    "        # get chromosome inds\n",
    "        _cid = int(_cid)\n",
    "        _cind = np.where(chr_ids == _cid)[0][0]\n",
    "        if np.array([_v[_cind]==[] for _k,_v in cell_cycle_flag_dict.items()]).any():\n",
    "            for _k,_v in cell_cycle_flag_dict.items():\n",
    "                if _k == _state:\n",
    "                    _v[_cind] = True\n",
    "                else:\n",
    "                    _v[_cind] = False\n",
    "    # append to data\n",
    "    for _k, _v in cell_cycle_flag_dict.items():\n",
    "        data_rep2[f'{_k}_flags'] = np.array(_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Save current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {rep1: data_rep1, rep2: data_rep2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== chr2.rep1 ========\n",
      "chrom_ids            ndarray    (3029,)\n",
      "region_names         ndarray    (935,)\n",
      "mid_position_Mb      ndarray    (935,)\n",
      "start_position_Mb    ndarray    (935,)\n",
      "end_position_Mb      ndarray    (935,)\n",
      "dna_zxys             ndarray    (3029, 935, 3)\n",
      "\n",
      "======== chr2.rep2_p_arm ========\n",
      "chrom_ids            ndarray    (4848,)\n",
      "region_names         ndarray    (357,)\n",
      "mid_position_Mb      ndarray    (357,)\n",
      "start_position_Mb    ndarray    (357,)\n",
      "end_position_Mb      ndarray    (357,)\n",
      "dna_zxys             ndarray    (4848, 357, 3)\n",
      "\n",
      "======== BOTH REPS ========\n",
      "params               dict       0\n",
      "\n",
      "\n",
      "Is 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\n",
      "chr2.rep1           : True\n",
      "chr2.rep2_p_arm     : True\n",
      "\n",
      "\n",
      "Are there weird rounding errors in 'start_position_Mb'?\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# [GC+] Assess data structure\n",
    "in_common = False\n",
    "for name, data in all_data.items():\n",
    "    print(f'\\n======== {name} ========')\n",
    "    for key, val in data.items():\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            in_common = True\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "\n",
    "if in_common:\n",
    "    print(f'\\n======== BOTH REPS ========')\n",
    "    for key, val in data_rep1.items():\n",
    "        if not (key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key])):\n",
    "            continue\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {val.shape}')\n",
    "        else:\n",
    "            print(f'{key.ljust(20, \" \")} {type(val).__name__.ljust(10, \" \")} {len(val)}')\n",
    "            \n",
    "\n",
    "print(\"\\n\\nIs 'chrom_ids' just an index, eg. np.arange(1, len(chrom_ids) + 1)'?\")\n",
    "for name, data in all_data.items():\n",
    "    if 'chrom_ids' in data:\n",
    "        tmp = np.array_equal(data_rep1['chrom_ids'], np.arange(1, len(data_rep1['chrom_ids']) + 1))\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[tmp])\n",
    "\n",
    "print(\"\\n\\nConfirm there aren't any weird rounding errors in 'start_position_Mb':\")\n",
    "for name, data in all_data.items():\n",
    "    if 'start_position_Mb' in data:\n",
    "        tmp = (data['start_position_Mb'] - np.round(data['start_position_Mb'], 4)) != 0\n",
    "        print(f\"{name.ljust(25, ' ')} \" + {True: '✓', False: '✗'}[~np.any(tmp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep1.dna_zxys.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.region_names.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.mid_position_Mb.npy\n",
      "/net/noble/vol5/user/gesine/repos/Chromatin_Analysis_2020_cell/sequential_tracing/data/in_progress/3d_coords/chr2/chr2.rep2_p_arm.dna_zxys.npy\n"
     ]
    }
   ],
   "source": [
    "# [GC+] SAVE in-progress files - numpy\n",
    "\n",
    "for name, data in all_data.items():\n",
    "    for key, val in data.items():\n",
    "        if len(val) == 0 or key in ('start_position_Mb', 'end_position_Mb') or np.array_equal(np.asarray(val).ravel(), np.arange(np.asarray(val).size) + 1):\n",
    "            continue\n",
    "        if key in data_rep1 and key in data_rep2 and np.array_equal(data_rep1[key], data_rep2[key]):\n",
    "            tmp = chrom\n",
    "        else:\n",
    "            tmp = name\n",
    "        if isinstance(val, dict):\n",
    "            pass\n",
    "        else:\n",
    "            key = key.replace('/', '-')\n",
    "            print(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"))\n",
    "            np.save(os.path.join(dir_3d_coords, f\"{tmp}.{key}.npy\"), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GC+] SAVE in-progress files - pickled\n",
    "with open(os.path.join(dir_3d_coords, rep1) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(dir_3d_coords, rep2) + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_rep2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "\n",
    "# with open(rep1_coords_file, 'rb') as handle:\n",
    "#     data_rep1 = pickle.load(handle)\n",
    "# with open(rep2_coords_file, 'rb') as handle:\n",
    "#     data_rep2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.0 corresponding regions for p and q arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # P and q arm crop\n",
    "# p_crop = slice(0, 357)\n",
    "# q_crop = slice(357, len(data_rep1['dna_zxys'][0]))\n",
    "# print(p_crop, q_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 generate imaging-based median distance and proximity frequency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import squareform, pdist\n",
    "# zxys_rep1_list = np.array(data_rep1['dna_zxys'])\n",
    "# distmap_rep1_list = np.array([squareform(pdist(_zxy)) for _zxy in zxys_rep1_list])\n",
    "# # calculate contact freq map\n",
    "# contact_th = 500\n",
    "# contact_rep1_map = np.sum(distmap_rep1_list<contact_th, axis=0) / np.sum(np.isnan(distmap_rep1_list)==False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69317f56bf404b67816c987021d07654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0968a5249b4849e5acdf5f7e19ae9cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [GC+] edited so I can SAVE in-progress files\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "zxys_rep1_list = np.array(data_rep1['dna_zxys'])\n",
    "\n",
    "distmap_rep1_list = np.concatenate([pdist(_zxy).reshape(1, -1) for _zxy in tqdm(zxys_rep1_list)])\n",
    "np.save(distmap_list_file, distmap_rep1_list) # [GC+] SAVE in-progress files\n",
    "\n",
    "distmap_rep1_list = np.array([squareform(distvec) for distvec in tqdm(distmap_rep1_list)])\n",
    "\n",
    "# generate median distance map\n",
    "median_distance_map_rep1 = np.nanmedian(distmap_rep1_list, axis = 0)\n",
    "np.save(median_distance_map_file, median_distance_map_rep1) # [GC+] SAVE in-progress files\n",
    "\n",
    "# generate contact map\n",
    "contact_th = 500\n",
    "contact_map_rep1 = np.sum(distmap_rep1_list<contact_th, axis=0) / np.sum(np.isnan(distmap_rep1_list)==False, axis=0)\n",
    "np.save(median_distance_map_file, contact_map_rep1) # [GC+] SAVE in-progress files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.gc Load in-progress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [GC+] LOAD in-progress files\n",
    "# distmap_combined_list = np.load(distmap_list_file)\n",
    "# median_distance_map_combined = np.load(median_distance_map_file)\n",
    "# contact_map_combined = np.load(median_distance_map_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
